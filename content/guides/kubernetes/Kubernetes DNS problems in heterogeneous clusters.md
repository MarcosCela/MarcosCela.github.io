---
title: "Kubernetes DNS problems in heterogeneous clusters"
date: 2019-02-04
description: "Things that can go wrong when u have K8s nodes with different Ubuntu versions (special mention to systemd-resolved)"
featured_image: "/images/ubuntu-beaver.png"
categories:
- Kubernetes
- DNS
- Troubleshoot
tags: ["kubernetes","dns"]
include_toc: true
---

## The symptoms

- Pods will not correctly perform DNS resolution, seemingly at random.
- One day everything is fine, the next day everything is on fire.
- Kube-dns pods show some restarts (2-3) in the last few days, these restarts
  are correlated to the problems, and indicate a bad restart. This means that SOMETIMES,
  when the kube-dns pod restarted, it did so in a bad state or configuration.
- Logs on kube-dns failed containers show an upstream DNS resolver of 127.0.0.53.

## The cause
In this case the restarts were due to a bad configuration on the **/etc/resolv.conf** file
inside the kube-dns pod.

A modern (Ubuntu 18.04) **/etc/resolv.conf** usually looks like this:
{{< highlight conf >}}
# This file is managed by man:systemd-resolved(8). Do not edit.
# This is a dynamic resolv.conf file for connecting local clients to the
# internal DNS stub resolver of systemd-resolved. This file lists all
# configured search domains.
# Run "systemd-resolve --status" to see details about the uplink DNS servers
# currently in use.
# Third party programs must not access this file directly, but only through the
# symlink at /etc/resolv.conf. To manage man:resolv.conf(5) in a different way,
# replace this symlink by a static file or a different symlink.
# See man:systemd-resolved.service(8) for details about the supported modes of
# operation for /etc/resolv.conf.

nameserver 127.0.0.53
{{< / highlight >}}

This should not bring up any alarms, since [systemd-resolved][systemd-resolved-manpage]
is the default network name resolution service for Ubuntu 18.

The problem with this configuration is that kube-dns copies the **/etc/resolv.conf** entry
of the host that it runs on. This means that when our kube-dns pod was bein scheduled
in the hefty Ubuntu 18 node, the kube-dns pod was malfunctioning, since it obviously didn't
had anything like [systemd-resolved][systemd-resolved-manpage] running inside the kube-dns pod!

Now there are several solutions to this:
 
 * You could force mount an explicit configmap for the
   kube-dns pod, forcing a specific nameserver entry.
 
 * You can change the contents of the **/etc/resolv.conf** files for each of your cluster's nodes,
   so they are valid even when being used inside a pod.
   
 * You can force the kube-dns pod to select nodes that have a valid **/etc/resolv.conf**.
 
 * Manually set the "--cluster-dns" kubelet flag to a list of DNS server IP address.
 
 * Pass the kubelet "--resolv-conf=<path>" to a different path (the one generated by systemd!).
 
 * Create a kube-dns ConfigMap with an upstream entry.
 
As with everything, there are several ways of solving the problem, even if some of them are shooting
yourself in the foot. Here we explore the route of generating a consistent configuration for 
all of the cluster nodes (ensure that /etc/resolv.conf is the same on every node).


## The solution

On the only node that had a "bad" **/etc/resolv.conf** we updated the systemd resolver to generate
a "valid" one.
Simply update the file **/etc/systemd/resolved.conf** to something like:

{{< highlight ini >}}
[Resolve]
DNS=10.1.1.10
FallbackDNS=10.1.1.20
Domains=company.local
{{< / highlight >}}

And force that **/etc/resolv.conf** uses the new generated file:
{{< highlight bash >}}
sudo ln -sf /run/systemd/resolve/resolv.conf /etc/resolv.conf
{{< / highlight >}}

With this all of the nodes should have a **/etc/resolv.conf** file that does not contain 
directions to _127.0.0.X_, that kube-dns will struggle to resolve, and our DNS configuration
should be up and working in no time.


[systemd-resolved-manpage]: http://manpages.ubuntu.com/manpages/bionic/man8/systemd-resolved.service.8.html

